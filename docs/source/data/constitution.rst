Constitution et Acquisition des Donn√©es
========================================

La constitution d'un dataset de qualit√© est fondamentale pour le succ√®s d'un projet de Computer Vision. 
Cette section d√©taille notre approche pour collecter et pr√©parer les donn√©es d'entra√Ænement.

Strat√©gie d'Acquisition
=======================

Notre strat√©gie s'articule autour de trois axes principaux :

1. **Collecte automatis√©e** via des outils de scraping web
2. **Diversification** des sources et types de contenu  
3. **Validation manuelle** pour garantir la qualit√©

.. mermaid::

   flowchart LR
       A[SerpAPI] --> B[Liste d'URLs]
       B --> C[Selenium + Chrome]
       C --> D[Captures d'√©cran]
       D --> E[~3000 images brutes]
       E --> F[Nettoyage manuel]
       F --> G[~2663 images finales]

D√©but de Constitution du Dataset
===============================

Capture via Selenium + undetected-chromedriver
-----------------------------------------------

La capture est effectu√©e avec un navigateur pilot√© par Selenium, combin√© √† ``undetected-chromedriver`` 
pour √©viter les blocages par Google ou les syst√®mes anti-automatisation.

.. code-block:: python

   from selenium import webdriver
   from undetected_chromedriver import Chrome
   
   # Configuration du navigateur
   options = webdriver.ChromeOptions()
   options.add_argument('--headless')
   options.add_argument('--window-size=1280,800')
   
   driver = Chrome(options=options)

Process de Collecte d'URLs
---------------------------

**√âtape 1 : G√©n√©ration d'URLs via SerpAPI**

.. code-block:: python

   # Requ√™tes utilis√©es pour la collecte
   queries = [
       "actualit√©s france",
       "articles de blog",
       "sites d'information", 
       "pages produits e-commerce",
       "documentation technique",
       "forums de discussion"
   ]

.. note::
   SerpAPI g√©n√®re des liens de pages existant sur internet √† partir de nos requ√™tes. 
   Pour chaque requ√™te, maximum 100 liens sont collect√©s et une sauvegarde des liens 
   est effectu√©e. Le code a √©t√© relanc√© 5 fois pour diversifier les sources.

**√âtape 2 : Configuration de la Capture**

.. list-table:: Param√®tres de Capture
   :header-rows: 1
   :widths: 30 70

   * - **Param√®tre**
     - **Valeur**
   * - Largeur fen√™tre
     - 1280 pixels
   * - Hauteur minimum
     - 800 pixels  
   * - Hauteur maximum
     - 10000 pixels
   * - Nombre de scrolls max
     - 30
   * - Temps de pause
     - 1 seconde

**√âtape 3 : Capture avec Scroll Progressif**

.. code-block:: python

   def capture_with_scroll(driver, url):
       driver.get(url)
       
       # Scroll progressif et fluide
       total_height = driver.execute_script("return document.body.scrollHeight")
       current_position = 0
       scroll_step = total_height // 30  # Max 30 scrolls
       
       while current_position < total_height:
           driver.execute_script(f"window.scrollTo(0, {current_position});")
           time.sleep(1)  # Pause pour le chargement
           current_position += scroll_step
       
       # Capture d'√©cran compl√®te
       return driver.get_screenshot_as_png()

**√âtape 4 : Sauvegarde et M√©tadonn√©es**

Chaque capture est sauvegard√©e avec :

* L'image au format PNG
* L'URL correspondante
* La timestamp de capture
* Les dimensions de la page
* Le statut de chargement

.. code-block:: json

   {
       "filename": "capture_001.png",
       "url": "https://example.com/article",
       "timestamp": "2025-06-16T10:30:00Z",
       "dimensions": {"width": 1280, "height": 3500},
       "status": "success"
   }

R√©sultats de la Collecte
========================

**Volume de Donn√©es Collect√©es**

.. grid:: 3

   .. grid-item-card:: üìä Images Brutes
      :text-align: center
      
      ~3000 captures initiales

   .. grid-item-card:: üßπ Apr√®s Nettoyage
      :text-align: center
      
      2663 images conserv√©es

   .. grid-item-card:: üéØ Prioris√©es
      :text-align: center
      
      Articles et vid√©os YouTube

Distribution des Tailles d'Images
----------------------------------

.. image:: ../_static/taille_distribution.png
   :width: 600px
   :align: center
   :alt: Distribution des tailles d'images collect√©es

.. warning::
   **D√©fis identifi√©s lors de la collecte :**
   
   * Certaines captures ont de tr√®s grandes tailles (> 5000px de hauteur)
   * Les captures tr√®s longues posaient des probl√®mes de RAM √† l'ouverture
   * Aucun redimensionnement appliqu√© par choix (pr√©servation de la r√©solution)

Types de Contenu Prioris√©s
===========================

1. **Articles de Presse et Blogs**
   
   * Structure claire avec titre, contenu, sidebar
   * Pr√©sence fr√©quente de publicit√©s
   * Bon √©quilibre des classes d'annotation

2. **Pages de Visualisation YouTube**
   
   * Interface standardis√©e
   * √âl√©ments sp√©cifiques : likes, vues, commentaires, recommandations
   * Excellent pour tester la pr√©cision du mod√®le

3. **Sites E-commerce**
   
   * Mise en page complexe
   * Nombreux √©l√©ments visuels (images produits, prix, avis)
   * Cas d'usage r√©aliste pour l'application

M√©thode de Nettoyage
====================

Le nettoyage manuel s'est concentr√© sur :

.. code-block:: none

   ‚úó Suppression des erreurs de domaine (pages d'erreur 404, 500)
   ‚úó √âlimination des captures vides ou corrompues  
   ‚úó Retrait des contenus non-pertinents (captchas, redirections)
   ‚úì Conservation des pages avec structure web classique
   ‚úì Priorisation du contenu textuel riche

**Crit√®res de Conservation :**

* Pr√©s
